{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFiWhGo12e_o"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14NnMBFNzg8S",
        "outputId": "f6441322-b131-43ee-e7d8-b8d09e7af0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8UYw-3Q_oVe",
        "outputId": "cc20e37a-a0b4-464c-8748-ec475a4e5bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oL7Nj8bmmAj",
        "outputId": "1707c2e6-5599-4a1e-f643-70ea033fb440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Driver Drowsiness Dataset (DDD).zip\n",
            "replace /content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/A0001.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/A0002.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/Driver Drowsiness Dataset (DDD).zip\" -d \"/content/drive/MyDrive/newdata/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa81ccb-91a6-47b6-aec5-e81cc3a18eda",
        "id": "MB0WOdU9xQeY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df\n",
            "(41793, 4)\n",
            "dfTest\n",
            "(2570, 4)\n",
            "dfWithout\n",
            "(39223, 4)\n",
            "testTO\n",
            "(2570, 2)\n"
          ]
        }
      ],
      "source": [
        "# Add image paths, labels, file names and person IDs into lists\n",
        "image_path, label, file_name, person_ID = [], [], [], []\n",
        "\n",
        "pattern = re.compile(r'^[a-zA-Z][a-zA-Z]?') #identification criteria of participant\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/\"\n",
        "\n",
        "for class_name in os.listdir(data_dir):  #goes through all folders in DDD folder\n",
        "  for path in os.listdir(data_dir+class_name):  #goes through all files in both folders and updates file path and labels\n",
        "    if class_name == 'Drowsy':\n",
        "      label.append(0)\n",
        "    else:\n",
        "      label.append(1)\n",
        "    image_path.append(os.path.join(data_dir, class_name, path))\n",
        "    file_name.append(path)\n",
        "\n",
        "    person_ID.append(pattern.findall(path)[0])  #identification of participant\n",
        "\n",
        "\n",
        "#dataframe with path, label, file name, person_ID of all Persons\n",
        "df = pd.DataFrame()\n",
        "df['images'] = image_path\n",
        "df['label'] = label\n",
        "df['name'] = file_name\n",
        "df['person'] = person_ID\n",
        "\n",
        "print('df')\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "#add Person E and G only to the Test Dataset\n",
        "dfTest = pd.concat([df[df['person']=='e'], df[df['person']=='g'], df[df['person']=='E'], df[df['person']=='G']]) #, df[df['person']=='S'], df[df['person']=='s']])\n",
        "print('dfTest')\n",
        "print(dfTest.shape)\n",
        "\n",
        "\n",
        "#remove Person E and G from the dataset with all Persons\n",
        "dfWithout = df\n",
        "dfWithout = dfWithout.drop(index=(df[df['person']=='e'].index))\n",
        "dfWithout = dfWithout.drop(index=(df[df['person']=='E'].index))\n",
        "dfWithout = dfWithout.drop(index=(df[df['person']=='g'].index))\n",
        "dfWithout = dfWithout.drop(index=(df[df['person']=='G'].index))\n",
        "\n",
        "#dfWithout = dfWithout.drop(index=(df[df['person']=='s'].index))\n",
        "#dfWithout = dfWithout.drop(index=(df[df['person']=='S'].index))\n",
        "\n",
        "print('dfWithout')\n",
        "print(dfWithout.shape)\n",
        "\n",
        "\n",
        "#converting imagepath and label of takeout persons G, E into an nparray\n",
        "imagePathTakeout = dfTest['images']\n",
        "labelTakeout = dfTest['label']\n",
        "\n",
        "imagePathTO = np.array(imagePathTakeout).reshape([-1,1])\n",
        "labelTO = np.array(labelTakeout).reshape([-1,1])\n",
        "testTO = np.hstack((imagePathTO, labelTO))\n",
        "\n",
        "print('testTO')\n",
        "print(testTO.shape)\n",
        "\n",
        "\n",
        "#converting imagepath and label of all other persons into an nparray\n",
        "imagePathWithout = dfWithout['images']\n",
        "labelWithout = dfWithout['label']\n",
        "\n",
        "image_path = np.array(imagePathWithout).reshape([-1,1])\n",
        "label = np.array(labelWithout).reshape([-1,1])\n",
        "comp_data = np.hstack((image_path, label))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testTO)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6CcT4Sknfqe",
        "outputId": "dda08745-133a-4545-e1a9-30e6ace2b818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Non Drowsy/e0382.png'\n",
            "  1]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Non Drowsy/e0399.png'\n",
            "  1]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Non Drowsy/e0415.png'\n",
            "  1]\n",
            " ...\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/G0534.png'\n",
            "  0]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/G0529.png'\n",
            "  0]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/G0525.png'\n",
            "  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"person\").size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzp6U8rpMrpW",
        "outputId": "23ac603c-c6d9-4e2e-d203-0ebd4a56867a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "person\n",
              "A     1411\n",
              "B      315\n",
              "C      335\n",
              "D      179\n",
              "E      962\n",
              "F      415\n",
              "G      499\n",
              "H      508\n",
              "I     1095\n",
              "J      474\n",
              "K      630\n",
              "L      732\n",
              "M      777\n",
              "N     1156\n",
              "O     1097\n",
              "P      963\n",
              "Q      562\n",
              "R      204\n",
              "S      487\n",
              "T      933\n",
              "U      420\n",
              "V      653\n",
              "W     1162\n",
              "X     1749\n",
              "Y     1112\n",
              "ZA     621\n",
              "ZB    1551\n",
              "ZC    1346\n",
              "a     1252\n",
              "b      409\n",
              "c      400\n",
              "d     1005\n",
              "e     1000\n",
              "g      109\n",
              "h      571\n",
              "i     1045\n",
              "j      717\n",
              "k      538\n",
              "l      381\n",
              "m      473\n",
              "n      957\n",
              "o      671\n",
              "p      190\n",
              "q      521\n",
              "r      522\n",
              "s      457\n",
              "u      510\n",
              "v     1002\n",
              "w      493\n",
              "x     1143\n",
              "y     1500\n",
              "za    1054\n",
              "zb    1237\n",
              "zc    1288\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m9YAiGrun_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b63f48-fb38-4e97-c42a-4d0c500d4822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainW\n",
            "(31378, 2)\n",
            "testW\n",
            "(7845, 2)\n",
            "test\n",
            "(10415, 2)\n",
            "[['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Non Drowsy/zb0371.png'\n",
            "  1]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/P0931.png'\n",
            "  0]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/ZB1536.png'\n",
            "  0]\n",
            " ...\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/X0938.png'\n",
            "  0]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/L0278.png'\n",
            "  0]\n",
            " ['/content/drive/MyDrive/newdata/Driver Drowsiness Dataset (DDD)/Drowsy/S0144.png'\n",
            "  0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#nparray with all other persons (except of E, G) gets split into train and test dataset\n",
        "trainW, testW = train_test_split(comp_data, test_size=0.2, random_state=1234)\n",
        "print('trainW')\n",
        "print(trainW.shape)\n",
        "\n",
        "print('testW')\n",
        "print(testW.shape)\n",
        "\n",
        "\n",
        "#train dataset\n",
        "train = trainW\n",
        "\n",
        "\n",
        "#test dataset is a combination of the takeout of person E, G and the part that was split to test via train_test_split\n",
        "test = np.concatenate((testTO, testW))\n",
        "\n",
        "\n",
        "print('test')\n",
        "print(test.shape)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DDDdataset(Dataset):\n",
        "  def __init__(self, image_paths, image_labels, transform):\n",
        "    super().__init__()\n",
        "    self.paths = image_paths\n",
        "    self.labels = image_labels\n",
        "    self.len = len(self.paths)\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self): return self.len\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    path = self.paths[index]\n",
        "    label = self.labels[index]\n",
        "    target_tensor=torch.from_numpy(np.array(label,dtype=np.int16))\n",
        "    #image = Image.open(path).convert('RGB')\n",
        "    image = cv2.imread(path,cv2.IMREAD_UNCHANGED)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = self.transform(image)\n",
        "    return (image, target_tensor, path)"
      ],
      "metadata": {
        "id": "CtupXG87cCc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transformation for the calculation of mean and std for the train dataset\n",
        "transformationCalc = transforms.Compose([\n",
        "    #ToTensor() includes an automatic scaling from the interval (0,255) to (0.0,1.0)\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#train dataset and loader for the calculation of mean and std for the train dataset\n",
        "trainDatasetCalc = DDDdataset(train[:,0], train[:,-1], transformationCalc)\n",
        "\n",
        "loaderCalc = DataLoader(trainDatasetCalc, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "ddyjWR-3cJzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfPixelsPerImage = 227*227\n",
        "noOfImages = train.shape[0]\n",
        "\n",
        "\n",
        "#lists to collect the sum of all pixel values in the batch for R, G, B\n",
        "sumOfBatchesR, sumOfBatchesG, sumOfBatchesB = [], [], []\n",
        "squaredSumOfBatchesR, squaredSumOfBatchesG, squaredSumOfBatchesB = [], [], []\n",
        "\n",
        "\n",
        "#in calcBatch(es) with 128 pictures each perform sum operations\n",
        "for calcBatch in loaderCalc:\n",
        "  #calcBatch[0] with dimension (128, 227, 227, 3)\n",
        "  currentBatch = calcBatch[0]\n",
        "  #currentBatch = currentBatch.float()\n",
        "\n",
        "\n",
        "  rgbSumOfBatch = currentBatch.sum(axis=2) #reduce column of one picture to one column (128, 227, 3)\n",
        "  rgbSumOfBatch = rgbSumOfBatch.sum(axis=1) #reduce row of one picture to one row (128, 3)\n",
        "  rgbSumOfBatch = rgbSumOfBatch.sum(axis=0) #combine all pictures of the batch to 3 values for rgb (3)\n",
        "  \n",
        "  #sum of the batch for R, G, B is stored for final calculation\n",
        "  sumOfBatchesR.append(rgbSumOfBatch[0])\n",
        "  sumOfBatchesG.append(rgbSumOfBatch[1])\n",
        "  sumOfBatchesB.append(rgbSumOfBatch[2])\n",
        "\n",
        "\n",
        "  rgbSquaredSumOfBatch = ((currentBatch)**2).sum(axis=2) #reduce column of one picture to one column (128, 227, 3)\n",
        "  rgbSquaredSumOfBatch = rgbSquaredSumOfBatch.sum(axis=1) #reduce row of one picture to one row (128, 3)\n",
        "  rgbSquaredSumOfBatch = rgbSquaredSumOfBatch.sum(axis=0) #combine all pictures of the batch to 3 values for rgb (3)\n",
        "\n",
        "  #squared sum of the batch for R, G, B is stored for final calculation\n",
        "  squaredSumOfBatchesR.append(rgbSquaredSumOfBatch[0])\n",
        "  squaredSumOfBatchesG.append(rgbSquaredSumOfBatch[1])\n",
        "  squaredSumOfBatchesB.append(rgbSquaredSumOfBatch[2])\n",
        "\n",
        "\n",
        "#final sum for R, G, B\n",
        "sumOfBatchesR = np.array(sumOfBatchesR).sum()\n",
        "sumOfBatchesG = np.array(sumOfBatchesG).sum()\n",
        "sumOfBatchesB = np.array(sumOfBatchesB).sum()\n",
        "\n",
        "#calculation of the mean for R, G, B\n",
        "meanR = sumOfBatchesR/(numberOfPixelsPerImage*noOfImages)\n",
        "meanG = sumOfBatchesG/(numberOfPixelsPerImage*noOfImages)\n",
        "meanB = sumOfBatchesB/(numberOfPixelsPerImage*noOfImages)\n",
        "\n",
        "#final squared sum for R, G, B\n",
        "squaredSumOfBatchesR = np.array(squaredSumOfBatchesR).sum()\n",
        "squaredSumOfBatchesG = np.array(squaredSumOfBatchesG).sum()\n",
        "squaredSumOfBatchesB = np.array(squaredSumOfBatchesB).sum()\n",
        "\n",
        "#final variance\n",
        "varianceR = (squaredSumOfBatchesR - ((sumOfBatchesR)**2)/(numberOfPixelsPerImage*noOfImages))/(numberOfPixelsPerImage*noOfImages)\n",
        "varianceG = (squaredSumOfBatchesG - ((sumOfBatchesG)**2)/(numberOfPixelsPerImage*noOfImages))/(numberOfPixelsPerImage*noOfImages)\n",
        "varianceB = (squaredSumOfBatchesB - ((sumOfBatchesB)**2)/(numberOfPixelsPerImage*noOfImages))/(numberOfPixelsPerImage*noOfImages)\n",
        "\n",
        "#final std of R, G, B\n",
        "stdR = math.sqrt(varianceR)\n",
        "stdG = math.sqrt(varianceG)\n",
        "stdB = math.sqrt(varianceB)\n",
        "\n",
        "print(meanR)\n",
        "print(meanG)\n",
        "print(meanB)\n",
        "print('---')\n",
        "print(stdR)\n",
        "print(stdG)\n",
        "print(stdB)\n",
        "  "
      ],
      "metadata": {
        "id": "Llcxfz0OHYov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80c70d7-0bb6-4f84-f23d-b3b2217d8c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.006184743944666335\n",
            "0.006139940288171414\n",
            "0.006088251754062657\n",
            "0.06234466895611421\n",
            "0.061939846592852496\n",
            "0.06151409079587224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meanR = 0.006185\n",
        "meanG = 0.006140\n",
        "meanB = 0.006088\n",
        "stdR = 0.06234\n",
        "stdG = 0.06194\n",
        "stdB = 0.06151"
      ],
      "metadata": {
        "id": "BxtU3bsqavwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssbwJ0mX1ZkX"
      },
      "outputs": [],
      "source": [
        "#transformation for model training and testing\n",
        "transformation = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[meanR, meanG, meanB], std=[stdR, stdG, stdB])\n",
        "])\n",
        "\n",
        "\n",
        "#datasets and dataloaders for model training and testing\n",
        "trainDataset = DDDdataset(train[:,0], train[:,-1], transformation)\n",
        "testDataset = DDDdataset(test[:,0], test[:,-1], transformation)\n",
        "\n",
        "trainDataLoader = DataLoader(trainDataset, batch_size=64, shuffle=True)\n",
        "testDataLoader = DataLoader(testDataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "--------------------------------\n",
        "number of parameters CNN below\n",
        "\n",
        "(II) f*f*ch_in*ch_out + ch_out_bias = params_conv_layer\n",
        "\n",
        "(III) numberOfInputImageElements*outputFeaturesCurrentFCLayer = params_fully_connected\n",
        "\n",
        "conv1: 4*4*3*10 + 10 = 490 -> 4*4 filter, 3 input image channels, 10 number of filters, +10 bias parameters of each filter\n",
        "conv2: 5*5*10*20 + 20 = 5020\n",
        "conv3: 6*6*20*32 + 32 = 23072\n",
        "conv4: 3*3*32*64 + 64 = 18496\n",
        "\n",
        "after conv4 layer: output \"image\": 3*3*64 = 576\n",
        "\n",
        "fc1: 576*250 + 250 = 144250 -> fc1 has 250 output features\n",
        "fc2: 250*50 + 50 = 12550\n",
        "fc3: 50*2 + 2 = 102\n",
        "\n",
        "complete CNN: 203980 parameters\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "F2rhmmMbrr7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY0t3t6Q1YV-"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(4,4), stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(10)\n",
        "    self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=(5,5), stride=2, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(20)\n",
        "    self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=(6,6), stride=2, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(32)\n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=1)\n",
        "    #self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=64*3*3, out_features=250)\n",
        "    #self.bn5 = nn.BatchNorm1d(250)\n",
        "    self.fc2 = nn.Linear(in_features=250, out_features=50)\n",
        "    self.bn6 = nn.BatchNorm1d(50)\n",
        "    self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    X = F.relu(self.bn1(self.conv1(X)))\n",
        "\n",
        "    X = F.max_pool2d(X, 2)\n",
        "\n",
        "    X = F.relu(self.bn2(self.conv2(X)))\n",
        "\n",
        "    X = F.max_pool2d(X, 2)\n",
        "\n",
        "    X = F.relu(self.bn3(self.conv3(X)))\n",
        "\n",
        "    X = F.max_pool2d(X, 3, stride=2)\n",
        "\n",
        "    X = F.relu(self.bn4(self.conv4(X)))\n",
        "\n",
        "    X = F.max_pool2d(X, 2)\n",
        "\n",
        "    X = X.view(X.shape[0], -1)\n",
        "    X = F.relu(self.bn5(self.fc1(X)))\n",
        "    X = F.relu(self.bn6(self.fc2(X)))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47OKopc4tK1K",
        "outputId": "bf347810-cccf-420b-e08a-98abc490fb64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- Epoch: 0, train loss: 0.0318, train acc: 0.9927, time: 5820.635276794434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-6d36089d14ce>:77: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if rowsOfWrongClassifications == []:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, test loss: 0.3710, test acc: 0.8644, time: 7559.003975391388\n",
            "\n",
            "\n",
            " --- Epoch: 1, train loss: 0.0086, train acc: 0.9967, time: 8586.196023225784\n",
            "Epoch: 1, test loss: 0.5604, test acc: 0.8842, time: 8766.524643421173\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "model = CNN()\n",
        "number_epochs = 2\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "\n",
        "#for the analysis of the wrong classifications\n",
        "pathsOfWrongClassifications = []\n",
        "rowsOfWrongClassifications = []\n",
        "correctLabel = []\n",
        "epochOfWrongClassification = []\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "#model training and testing process\n",
        "for epoch in range(number_epochs):\n",
        "\n",
        "  #\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "  \n",
        "  #-------model training-------\n",
        "  for (X, y, path) in trainDataLoader:\n",
        "    X = torch.as_tensor(X)\n",
        "    y = torch.as_tensor(y)\n",
        "    predictions = model(X)\n",
        "    loss = loss_func(predictions, y.long())\n",
        "\n",
        "    #adaption of the neural network\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #\n",
        "    accuracy = ((predictions.argmax(dim=1) == y).float().mean())\n",
        "    epoch_accuracy += accuracy\n",
        "    epoch_loss += loss\n",
        "  \n",
        "  #total epoch_accuracy and epoch_loss calculation\n",
        "  epoch_accuracy = epoch_accuracy/len(trainDataLoader)\n",
        "  accuracies.append(epoch_accuracy)\n",
        "  epoch_loss = epoch_loss / len(trainDataLoader)\n",
        "  losses.append(epoch_loss)\n",
        "\n",
        "  print(\"\\n --- Epoch: {}, train loss: {:.4f}, train acc: {:.4f}, time: {}\".format(epoch, epoch_loss, epoch_accuracy, time.time() - start))\n",
        "  #-------model training-------\n",
        "  \n",
        "  \n",
        "  #---model testing---\n",
        "  model.eval() #sets the model in evaluation mode\n",
        "  \n",
        "  #with disabled gradient calculation\n",
        "  with torch.no_grad():\n",
        "    test_epoch_loss = 0\n",
        "    test_epoch_accuracy = 0\n",
        "\n",
        "    for test_X, test_y, path in testDataLoader:\n",
        "\n",
        "      test_preds = model(test_X)\n",
        "      #print(test_preds.shape)\n",
        "      #print(test_preds)\n",
        "      test_loss = loss_func(test_preds, test_y.long())\n",
        "\n",
        "      test_epoch_loss += test_loss            \n",
        "      test_accuracy = ((test_preds.argmax(dim=1) == test_y).float().mean())\n",
        "      test_epoch_accuracy += test_accuracy\n",
        "\n",
        "      #if test prediction is wrong save the path of the image that has been classified wrong\n",
        "      for index, row in enumerate(test_preds):\n",
        "        if row.argmax(dim=0) != test_y[index]:\n",
        "          pathsOfWrongClassifications.append(path[index])\n",
        "          if rowsOfWrongClassifications == []:\n",
        "            rowsOfWrongClassifications = row\n",
        "          else:\n",
        "            rowsOfWrongClassifications = np.vstack([rowsOfWrongClassifications, row])\n",
        "          correctLabel.append(test_y[index].item())\n",
        "          epochOfWrongClassification.append(epoch)\n",
        "\n",
        "    #total test_epoch_accuracy and test_epoch_loss calculation\n",
        "    test_epoch_accuracy = test_epoch_accuracy/len(testDataLoader)\n",
        "    test_epoch_loss = test_epoch_loss / len(testDataLoader)\n",
        "\n",
        "    print(\"Epoch: {}, test loss: {:.4f}, test acc: {:.4f}, time: {}\\n\".format(epoch, test_epoch_loss, test_epoch_accuracy, time.time() - start))\n",
        "  #---model testing---\n",
        "\n",
        "  model.train(mode=True) #sets the model back in training mode\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np_rows = np.array(rowsOfWrongClassifications)\n",
        "\n",
        "#extract the person ID out of the stored image paths\n",
        "personID = []\n",
        "for pathStr in pathsOfWrongClassifications:\n",
        "  personID.append(pathStr[pathStr.rfind('/')+1:-8])\n",
        "\n",
        "\n",
        "#create a dataframe from all wrong classified images in the test dataset\n",
        "dfWrong = pd.DataFrame()\n",
        "dfWrong['testEpochNo'] = epochOfWrongClassification\n",
        "dfWrong['personID'] = personID\n",
        "dfWrong['imagepath'] = pathsOfWrongClassifications\n",
        "dfWrong['correctLabel'] = correctLabel\n",
        "dfWrong['outputValueLabel0'] = rowsOfWrongClassifications[:,0]\n",
        "dfWrong['outputValueLabel1'] = rowsOfWrongClassifications[:,1]\n",
        "\n",
        "print(dfWrong)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YWg6fM1IoVT",
        "outputId": "661cda52-78a4-4160-cca1-d2a2e5c2dc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      testEpochNo personID                                          imagepath  \\\n",
            "0               0        E  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "1               0        E  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "2               0        E  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "3               0        E  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "4               0        G  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "...           ...      ...                                                ...   \n",
            "2614            1        e  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "2615            1        e  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "2616            1        G  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "2617            1        e  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "2618            1        e  /content/drive/MyDrive/newdata/Driver Drowsine...   \n",
            "\n",
            "      correctLabel  outputValueLabel0  outputValueLabel1  \n",
            "0                0          -0.676776           1.235571  \n",
            "1                0          -1.027923           1.638908  \n",
            "2                0          -1.086451           1.710287  \n",
            "3                0          -0.503722           1.099228  \n",
            "4                0          -0.056409           0.760952  \n",
            "...            ...                ...                ...  \n",
            "2614             1           2.719177          -2.212409  \n",
            "2615             1           2.582422          -2.085087  \n",
            "2616             0           0.082866           0.297966  \n",
            "2617             1           3.230270          -2.673494  \n",
            "2618             1           3.332798          -2.739567  \n",
            "\n",
            "[2619 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get an overview of the persons that are likely to be classified in a wrong way\n",
        "dfOfEpoch1 = dfWrong[dfWrong['testEpochNo']==1]\n",
        "dfOfEpoch1.groupby('personID').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pg3VzoDQBqb",
        "outputId": "e8406d88-fe60-457d-adc8-613a6b9affd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "personID\n",
              "E       5\n",
              "G      48\n",
              "b       7\n",
              "c       1\n",
              "e    1000\n",
              "g      97\n",
              "n      10\n",
              "o       2\n",
              "r       2\n",
              "s      18\n",
              "u       8\n",
              "w       5\n",
              "x       1\n",
              "y       3\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results of different trials:\n",
        "\n",
        "\n",
        "I)\n",
        "\n",
        "persons that have been shifted totally to the training dataset:\n",
        "e, E, g, G\n",
        "\n",
        "wrong classifications:\n",
        "\n",
        "E: 5/962 = 0.5%\n",
        "\n",
        "G: 48/499 = 9.6%\n",
        "\n",
        "e: 1000/1000 = 100%\n",
        "\n",
        "g: 97/109 = 89.0%\n",
        "\n",
        "s: 18/457 = 3,9%\n",
        "\n",
        "S: 0/487 = 0.0%\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HTPa784Zi5rj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}